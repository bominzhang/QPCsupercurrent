{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import functools\n",
    "from glob import glob\n",
    "import inspect\n",
    "from itertools import product\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from toolz import partition_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sys.version_info >= (3, 6), 'Use Python â‰¥3.6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upd(d, **kwargs):\n",
    "    # Update a `dict` inline and return the `dict`.\n",
    "    d = d.copy()\n",
    "    for k, v in kwargs.items():\n",
    "        d[k] = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(lview, func, vals, parameters, fname_i, N=None,\n",
    "                   overwrite=False):\n",
    "    \"\"\"Run a simulation where one loops over `vals`. The simulation\n",
    "    yields len(vals) results, but by using `N`, you can split it up\n",
    "    in parts of length N.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lview : ipyparallel.client.view.LoadBalancedView object\n",
    "        LoadBalancedView for asynchronous map.\n",
    "    func : function\n",
    "        Function that takes a list of arguments: `vals`.\n",
    "    vals : list\n",
    "        Arguments for `func`.\n",
    "    parameters : dict\n",
    "        Dictionary that is saved with the data, used for constant\n",
    "        parameters.\n",
    "    fname_i : str\n",
    "        Name for the resulting HDF5 files. If the simulation is\n",
    "        split up in parts by using the `N` argument, it needs to\n",
    "        be a formatteble string, for example 'file_{}'.\n",
    "    N : int\n",
    "        Number of results in each pandas.DataFrame.\n",
    "    overwrite : bool\n",
    "        Overwrite the file even if it already exists.\n",
    "    \"\"\"\n",
    "    if N is None:\n",
    "        N = 1000000\n",
    "        if len(vals) > N:\n",
    "            raise Exception('You need to split up vals in smaller parts')\n",
    "\n",
    "    N_files = len(vals) // N + (0 if len(vals) % N == 0 else 1)\n",
    "    print('`vals` will be split in {} files.'.format(N_files))\n",
    "    time_elapsed = 0\n",
    "    parts_done = 0\n",
    "    for i, chunk in enumerate(partition_all(N, vals)):\n",
    "        fname = fname_i.replace('{}', '{:03d}').format(i)\n",
    "        print('Busy with file: {}.'.format(fname))\n",
    "        if not os.path.exists(fname) or overwrite:\n",
    "            map_async = lview.map_async(func, chunk)\n",
    "            map_async.wait_interactive()\n",
    "            result = map_async.result()\n",
    "            df = pd.DataFrame(result)\n",
    "            df = df.assign(**parameters)\n",
    "            df = df.assign(git_hash=get_git_revision_hash())\n",
    "            os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "            df.to_hdf(fname, 'all_data', mode='w', complib='zlib', complevel=9)\n",
    "\n",
    "            # Print useful information\n",
    "            N_files_left = N_files - (i + 1)\n",
    "            parts_done += 1\n",
    "            time_elapsed += map_async.elapsed\n",
    "            time_left = timedelta(seconds=(time_elapsed / parts_done) *\n",
    "                                  N_files_left)\n",
    "            print_str = ('Saved {}, {} more files to go, {} time left '\n",
    "                         'before everything is done.')\n",
    "            print(print_str.format(fname, N_files_left, time_left))\n",
    "        else:\n",
    "            print('File: {} was already done.'.format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_var_name(func, from_name, to_name):\n",
    "    sig = inspect.signature(func)\n",
    "    pars = [(name, value) for name, value in sig.parameters.items()]\n",
    "\n",
    "    new_pars = []\n",
    "    for k, v in pars:\n",
    "        if k is not from_name:\n",
    "            new_pars.append(v)\n",
    "        else:\n",
    "            new_pars.append(inspect.Parameter(to_name, v.kind,\n",
    "                                              default=v.default))\n",
    "\n",
    "    def wrapped(*args, **kwargs):\n",
    "        kwargs[from_name] = kwargs.pop(to_name)\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    wrapped.__signature__ = inspect.Signature(parameters=new_pars)\n",
    "\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_params(params):\n",
    "    for k, v in params.items():\n",
    "        if isinstance(v, str):\n",
    "            try:\n",
    "                params[k] = eval(v)\n",
    "            except NameError:\n",
    "                pass\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dfs(pattern, fname=None):\n",
    "    files = glob(pattern)\n",
    "    df = pd.concat([pd.read_hdf(f) for f in sorted(files)])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    if fname is not None:\n",
    "        os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "        df.to_hdf(fname, 'all_data', mode='w', complib='zlib', complevel=9)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_from_syst(syst):\n",
    "    lats = set(s.family for s in syst.sites)\n",
    "    if len(lats) > 1:\n",
    "        raise Exception('No unique lattice in the system.')\n",
    "    return list(lats)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoize(obj):\n",
    "    cache = obj.cache = {}\n",
    "\n",
    "    @functools.wraps(obj)\n",
    "    def memoizer(*args, **kwargs):\n",
    "        key = str(args) + str(kwargs)\n",
    "        if key not in cache:\n",
    "            cache[key] = obj(*args, **kwargs)\n",
    "        return cache[key]\n",
    "    return memoizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_product(**items):\n",
    "    names = items.keys()\n",
    "    vals = items.values()\n",
    "    return [dict(zip(names, res)) for res in product(*vals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_revision_hash():\n",
    "    \"\"\"Get the git hash to save with data to ensure reproducibility.\"\"\"\n",
    "    git_output = subprocess.check_output(['git', 'rev-parse', 'HEAD'])\n",
    "    return git_output.decode(\"utf-8\").replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    \"\"\"Find the nearest value in an array to a specified `value`.\"\"\"\n",
    "    idx = np.abs(np.array(array) - value).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unhashable_columns(df):\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if not hashable(df[col].iloc[0]):\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashable(v):\n",
    "    \"\"\"Determine whether `v` can be hashed.\"\"\"\n",
    "    try:\n",
    "        hash(v)\n",
    "    except TypeError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_constant_columns(df):\n",
    "    \"\"\"Taken from http://stackoverflow.com/a/20210048/3447047\"\"\"\n",
    "    df = remove_unhashable_columns(df)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df.loc[:, (df != df.ix[0]).any()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
